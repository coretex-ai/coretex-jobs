id: microbiome-forensics-body-site-prediction-xgb
name: Microbiome Forensics -> Body Site Prediction - XGBoost
description: "Body site prediction task template is based on XGBoost (gradient\r\n\
  boosting) algorithm.\r\n\r\nThis template takes BioInformatics sequence taxonomic\
  \ compositions\r\nand traines a model which is capable of predicting body site (from\
  \ which the\r\nsample originates) based on the sample taxonomic composition.\r\n\
  \r\nData provided to the model can be in either of these two formats:\r\n    - MBA\
  \ (Microbiome Atlas)\r\n    - ForBiome (Microbiome Forensics Institute Zurich)\r\
  \n\_\r\nInput of the model is a 2D matrix with input shape [samples, uniqueTaxons]\
  \ where:\r\n    - samples: number of samples in the dataset,\r\n    - uniqueTaxons:\
  \ number of unique taxons in the dataset\r\n\r\nOutput of the model is a 1D array\
  \ with integers representing different bodysites.\r\n\r\nExpected TaskRun runtime\
  \ on CPU with ~1 GB of MBA data is ~4m 22s.\r\nExpected TaskRun runtime on GPU with\
  \ ~1 GB of MBA data is ~3m 19s.\r\n\r\nSystem specifications on which the TaskRuns\
  \ were run:\r\n    - CPU: AMD Ryzen 7 1800X Eight-Core Processor\r\n    - GPU: Nvidia\
  \ GeForce GTX 1080 Ti 12 GB VRAM\r\n    - RAM: 32 GB 2666 MHz DDR4\r\n\r\nTaskRun\
  \ parameters:\r\n    - Percentile: 100\r\n    - Quantize: False\r\n    - Epochs:\
  \ 100\r\n    - Early stopping: 0\r\n    - Cache: False\r\n    - Enviromnment: Clean"
is_active: true
project_type: 11
param_groups:
- name: inputs
  params:
  - name: dataset
    description: "A dataset which contains OTU abundance data. Supported dataset formats\
      \ are:\r\n    - MBA (Microbiome Atlas): Dataset must contain one Coretex.ai\
      \ sample\r\n      with \"samples.env.info\" file, and one or more Coretex.ai\
      \ samples\r\n      which contain a single \".mapped\" file (file with \".mapped\"\
      \ extension)\r\n    - ForBiome (Microbiome Forensics Institute Zurich): Dataset\
      \ must contain\r\n      BioInformatics samples in json format as defined by\
      \ \"Microbiome Forensics\r\n      Institute Zurich\". Coretex.ai sample must\
      \ contain only a single json file\r\n      which contains data for a single\
      \ BioInformatics sample."
    value: 6327
    data_type: dataset
    required: true
  - name: trainedModel
    description: "Id of the model on which the validation will run.\r\nIf validation\
      \ mode is selected this parameter must be provided,\r\nand if training mode\
      \ is selected this parameter will be ignored."
    value: null
    data_type: model
    required: false
- name: outputs
  params:
  - name: outputModel
    description: Model trained by this task.
    value: null
    data_type: model
    required: false
- name: parameters
  params:
  - name: validation
    description: "Defines if TaskRun will be run in training or validation mode.\r\
      \nIf the value is set to false (unchecked) training mode will run,\r\nand if\
      \ the value is set to true (checked) then validation mode will be run.\r\n\r\
      \nIf training mode is selected following parameters must be provided:\r\n  \
      \  - dataset\r\n    - validation (value: false)\r\n    - datasetType\r\n   \
      \ - taxonomicLevel\r\n    - sampleOrigin\r\n    - percentile\r\n    - quantize\r\
      \n    - sequencingTechnique\r\n    - learningRate\r\n    - epochs\r\n    - earlyStopping\r\
      \n    - validationSplit\r\n    - useGpu\r\n    - cache\r\n\r\nIf validation\
      \ mode is selected following parameters must be provided:\r\n    - dataset\r\
      \n    - validation (value: true)\r\n    - trainedModel\r\n    - datasetType\r\
      \n    - taxonomicLevel\r\n    - sampleOrigin\r\n    - quantize\r\n    - sequencingTechnique\r\
      \n    - cache"
    value: false
    data_type: bool
    required: true
  - name: datasetType
    description: "Type of the provided dataset. Possible values are:\r\n    - MBA\
      \ (Microbiome Atlas)\r\n    - ForBiome (Microbiome Forensics Institute Zurich)\r\
      \n\r\nFor more details see \"dataset\" parameter."
    value: 0
    data_type: int
    required: true
  - name: taxonomicLevel
    description: "Taxonomic level used for creating OTU (feature) tables used as\r\
      \nthe input of the model. Expected value is a non-negative integer.\r\n\r\n\
      Expected values for taxon \"B16S;90_3084;96_8430;97_10076\":\r\n    - Level\
      \ 1: \"B16S\"\r\n    - Level 2: \"B16S;90_3084\"\r\n    - Level 3: \"B16S;90_3084;96_8430\""
    value: 1
    data_type: int
    required: true
  - name: sampleOrigin
    description: "Information on where sample originates from, the environment from\r\
      \nwhich the sample was collected from.\r\n\r\nExample values are: animal, plant,\
      \ aquatic, human, soil, field, etc."
    value:
    - human
    data_type: list[str]
    required: true
  - name: percentile
    description: "Amount of features which are kept for training. Value of the parameter\
      \ is\r\nexpressed in percents (%) from 1 - 100. The most representative features\
      \ are kept."
    value: 100
    data_type: int
    required: true
  - name: quantize
    description: "If set to true (checked) then lower precision (uint16 instead of\
      \ int32) will\r\nbe used for storing taxon count. Setting this value to true\
      \ can improve model\r\nperformance, but it can decrease model accuracy."
    value: false
    data_type: bool
    required: true
  - name: sequencingTechnique
    description: "Sample sequencing techniques which were used to seqeuence the samples.\r\
      \nPossible values are:\r\n    - AMPLICON\r\n    - SHOTGUN\r\n    - WGS\r\n\r\
      \nIf value is set to \"AMPLICON\" then all samples which were sequenced using\r\
      \nthat method will be used for further processing."
    value:
    - AMPLICON
    - SHOTGUN
    - WGS
    data_type: list[str]
    required: true
  - name: learningRate
    description: "Learning rate of the gradiend boosting algorithm. Prefered range\
      \ of values\r\nis 10^-6 (0,000001) - 1.0. Higher learning rates allow model\
      \ to train faster,\r\nbut at the cost of final model accuracy. Lower learning\
      \ rates make\r\nmodel train significantly slower, but in a more optimal manner."
    value: 0.3
    data_type: float
    required: true
  - name: epochs
    description: "Number of passes that the model will make through the dataset while\r\
      \ntraining. Higher values increase training time and accuracy, while lower\r\
      \nvalues decrease training time, but they might also decrease accuracy."
    value: 100
    data_type: int
    required: true
  - name: earlyStopping
    description: "Defines how many consecutive epochs should pass during which the\
      \ model hasn't\r\nlearned anything (loss reduction was minimal or non-existent)\
      \ before the training\r\nwill stop.\r\n\r\nAfter the training has stopped this\
      \ way, the final model will be picked from the\r\nlast N (defined by earlyStopping\
      \ value) epochs, taking the model (weights) from\r\nthe epoch which had the\
      \ highest learning rate (lowest loss)."
    value: 0
    data_type: int
    required: true
  - name: validationSplit
    description: "Percentage of dataset which will be used for validation. Prefered\
      \ value range is\r\n0.1 - 0.9, while the optimal value is 0.2. If values are\
      \ close or equal to 0, or\r\nclose or equal to 1 unexpected errors can appear.\r\
      \n\r\nIf value for \"validationSplit\" is 0.2, then that means that 20% of the\
      \ dataset\r\nwill go for validation, while the rest (80%) will go for training."
    value: 0.2
    data_type: float
    required: true
  - name: useGpu
    description: "If set to true (checked) the GPU will be used for training, otherwise\
      \ CPU\r\nwill be used.\r\n\r\nUsing GPU for training can decrease training time\
      \ significantly."
    value: false
    data_type: bool
    required: true
  - name: cache
    description: "If set to true (checked) processed dataset will be cached to speed\
      \ up the\r\nfollowing runs of the task which uses the same dataset and parameter\r\
      \nconfigurations.\r\n\r\nCaching is only implemented for MBA (Microbiome Atlas)\
      \ data. It is done in\r\ntwo steps:\r\n    1. MBA data is loaded into python\
      \ objects which are then pickled and\r\n       uploaded to Coretex.ai as a dataset.\
      \ This cache depends on\r\n       \"sampleOrigin\" and \"sequencingTechnique\"\
      \ parameters.\r\n    2. Processed model input and output data is pickled and\
      \ uploaded to\r\n       Coretex.ai just before training has started. This cache\
      \ depends on\r\n       the same parameters as the 1st step cache, as well as\
      \ \"quantize\" and\r\n       \"percentile\" parameters"
    value: false
    data_type: bool
    required: true
