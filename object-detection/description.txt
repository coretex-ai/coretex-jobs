--- Template description ---

Object Detection job template is based on YoloV5 model (https://github.com/ultralytics/yolov5).
YoloV5 is a state of the art (SOTA) model for running object detection on images.

Input of the model is an RGB image with pixel values normalized in range (0 - 1).
Training (Torch model) input shape is [batchSize, channels, height, width] where:
    - batchSize: number of images in a given batch
    - channels: number of image channels, and currently it is set to 3 which represents RGB image
    - height: image height
    - width: image width

Exported (Tensorflow / JS model) input shape is [batchSize, height, width, channels]

Output of the model is an array of 4 different values:
    - Index 0: Bounding boxes
    - Index 1: Scores (range: 0 - 1) - how confident model is for the detected class
    - Index 2: Class of the detection
    - Index 3: Number of (valid) detections after performing NMS (Non-maximum suppression)

Expected runtime on CPU is ~36m 17s.
    - CPU: 2.3GHz 8-core 9th-generation Intel Core i9
    - RAM: 16 GB 2667 MHz DDR4

Expected runtime on GPU is ~7m 49s. System specifications:
    - CPU: AMD Ryzen 7 1800X Eight-Core Processor
    - GPU: Nvidia GeForce GTX 1080 Ti 12 GB VRAM
    - RAM: 32 GB 2666 MHz DDR4

Run parameters:
    - Image count: 91
    - Epochs: 10
    - Batch size: 16
    - Image size: 640x640
    - Environment: Clean

----------------------------

--- Parameter descriptions ---

--- dataset description ---
A dataset which contains images and annotations which are represented by Coretex.ai
image annotation format.
---------------------------

--- augmentationDatasetId description ---
A dataset which contains images used for augmenting dataset used for training the model.
Augmentation is performed in a way where annotations are extracted from dataset images
and pasted on the images from "augmentationDatasetId" parameter.
-----------------------------------------

--- rotationAngle description ---
Angle by which the annotation will be rotated during the augmentation process.
Value is represented in degrees. Expected range of values is 0 - 360.
---------------------------------

--- scaleFactor description ---
Factor by which the annotation size will be scaled during the augmentation process.
Behaviour based on values:
    - if the value is equal to 1 annotation size remains unchanged
    - if the value is bigger than 1 annotation size will increase
    - if the value is smaller than 1 annotation size will decrease
-------------------------------

--- epochs description ---
Number of passes that the model will make through the dataset while
training. Higher values increase training time and accuracy, while lower
values decrease training time, but they might also decrease accuracy.
--------------------------

--- batchSize description ---
Number of segments into which the dataset is split before the training.
During the training a single epoch passes through all of the segments
before moving on to the next epoch. Higher values decrease training time,
but will increase memory consumption, while lower values increase training
time, but decrease memory consumption.
-----------------------------

--- imageSize description ---
Size to which the images from the dataset will be resized to before training.
This affects input and output shapes of the model. Input and output image shapes
will be equal to "imageSize * imageSize * 3" where imageSize represents both width
and height of the image, while number 3 (RGB image) represents the number of channels.

Higher values increase training time, but they can increase model accuracy, while lower
values decrease training time, but they also can decrease model accuracy.
-----------------------------

--- learningRate description ---
The learning rate determines the step size at which the model adjusts its weights during training.
It directly impacts how quickly or slowly the model converges during training.
A high learning rate can lead to overshooting and instability, while a low learning rate may cause slow convergence and prolonged training times.

Finding the right learning rate is crucial for optimizing the model's performance.
-----------------------------

--- weightDecay description ---
Weight decay, also known as L2 regularization, is a regularization technique used to prevent overfitting.
It adds a penalty term to the loss function based on the magnitude of the model's weights.
This encourages the model to have smaller weight values and helps in generalization.

A too high weight decay might result in underfitting, while a too low value might lead to overfitting.
-----------------------------

--- momentum description ---
Momentum is a parameter that helps to accelerate gradient descent in the relevant direction and dampens oscillations.
It keeps a moving average of gradients and helps the model to avoid getting stuck in local minima.
Appropriate momentum values usually lie between 0.8 to 0.99.

A momentum value too high might cause instability, while a value too low might slow down convergence.
-----------------------------

--- weightsUrl description ---
URL of the weights (model checkpoint) which will be used for training. This must
be a URL to a downloadable file supported by YoloV5 model.
------------------------------

--- validationSplit description ---
Percentage of dataset which will be used for validation. Prefered value range is
0.1 - 0.9, while the optimal value is 0.2. If values are close or equal to 0, or
close or equal to 1 unexpected errors can appear.

If value for "validationSplit" is 0.2, then that means that 20% of the dataset
will go for validation, while the rest (80%) will go for training.
-----------------------------------

--- excludedClasses description ---
Classes which will be excluded from the dataset when the training process starts.
-----------------------------------

--- modelId description ---
ID of model that will be fetched from Coretex platform and used for validation.
-----------------------------------

--- validation description ---
Paramter that determines mode of run. If set to true validation mode is started,
if set to false training mode is started.
-----------------------------------

------------------------------
